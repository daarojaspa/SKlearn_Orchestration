{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5548b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt  # Fixed: 'matplotlib as plt' → 'matplotlib.pyplot as plt'\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler  # Fixed: 'StandarScaler' → 'StandardScaler'\n",
    "from sklearn.linear_model import RANSACRegressor,HuberRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "path=\"/home/dan/PLATZI/data/SKlearn_Orchestration/skLearn_Orchestration/data/third_part/\"\n",
    "file=\"felicidad.csv\"\n",
    "df=pd.read_csv(path+file)\n",
    "n=rd.randint(4,10)\n",
    "m=df.shape[1]\n",
    "fill_mode=rd.choice([\"zeros\",\"towhundreds\",\"half and half\"])\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "\n",
    "n = rd.randint(4, 10)\n",
    "m = df.shape[1]\n",
    "fill_mode = rd.choice([\"zeros\", \"towhundreds\", \"half and half\"])\n",
    "\n",
    "if fill_mode == \"zeros\":\n",
    "    temp = np.zeros((n, m))\n",
    "    df = pd.concat([df, pd.DataFrame(temp, columns=df.columns)], axis=0)\n",
    "\n",
    "elif fill_mode == \"towhundreds\":\n",
    "    temp = np.ones((n, m)) * 200\n",
    "    df = pd.concat([df, pd.DataFrame(temp, columns=df.columns)], axis=0)\n",
    "\n",
    "else:\n",
    "    half_n = n // 2\n",
    "    temp1 = np.zeros((half_n, m))\n",
    "    temp2 = np.ones((n - half_n, m)) * 100\n",
    "    temp = np.vstack([temp1, temp2])\n",
    "    df = pd.concat([df, pd.DataFrame(temp, columns=df.columns)], axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cea11cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df=df.drop([\"country\",\"rank\", \"high\",\"low\",\"score\"], axis=1)\n",
    "target=df[\"score\"]\n",
    "features_df.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb89b8",
   "metadata": {},
   "source": [
    "### Ransac \n",
    "\n",
    "iterates a linear regration between all data points to find the one that adjust the best for most of the data (not trying to minimize and abrage error but residduals)  then pick the best fitting line and thats how outliers are found  and let out from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e122a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "SVR\n",
      "MSE: 193.41941101147688\n",
      "================================================================\n",
      "RANSAC\n",
      "MSE: 8780.594955231849\n",
      "================================================================\n",
      "Huber\n",
      "MSE: 0.27618319808675873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/envs/sklearnProject/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features_df, target, test_size=0.25, random_state=37)\n",
    "estimators={\n",
    "    \"SVR\": SVR (gamma = \"auto\",C=1,epsilon=0.1),\n",
    "    # is the penalization facto\n",
    "    # epcilon the margin of error is not penalice  \"soft margin\"\n",
    "    #gamma it has to doo with the  kernel to define the boundury\n",
    "    'RANSAC':RANSACRegressor(), #you can change the base _model \n",
    "    'Huber':HuberRegressor(epsilon=1.35)\n",
    "}\n",
    "for name, estimator in estimators.items():\n",
    "     estimator.fit(X_train,Y_train)\n",
    "     prediction = estimator.predict(X_test)\n",
    "     print('='*64)\n",
    "     print(name)\n",
    "     print (\"MSE:\",mean_squared_error(Y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d307cf",
   "metadata": {},
   "source": [
    "### Huber Regressor\n",
    "\n",
    "Penalizes the outliers instead of letting them dominate the fit,  \n",
    "using a threshold named **epsilon**, which is set to **1.35** by default.\n",
    "\n",
    "It combines the **Mean Squared Error (MSE)** and the **Median Absolute Deviation (MAD)** error.\n",
    "\n",
    "Steps:\n",
    "- Initialize coefficients.\n",
    "- Calculate residuals using both methods (MSE and MAD).\n",
    "- Scale the ones calculated via MAD.\n",
    "- Then calculate the **scaled residuals**.\n",
    "- **Epsilon** is the final boundary that determines whether an error is treated as MSE or MAD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633e6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa74d0c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearnProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
